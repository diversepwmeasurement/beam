concurrency:
  cancel-in-progress: true
  group: ${{ github.workflow }} @ ${{ github.event.issue.number || github.sha || github.head_ref
    || github.ref }}-${{ github.event.schedule || github.event.comment.id || github.event.sender.login
    }}
env:
  DEVELOCITY_ACCESS_KEY: ${{ secrets.GE_ACCESS_TOKEN }}
  GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}
  GRADLE_ENTERPRISE_CACHE_USERNAME: ${{ secrets.GE_CACHE_USERNAME }}
  INFLUXDB_USER: ${{ secrets.INFLUXDB_USER }}
  INFLUXDB_USER_PASSWORD: ${{ secrets.INFLUXDB_USER_PASSWORD }}
jobs:
  beam_PerformanceTests_ParquetIOIT_HDFS:
    if: 'github.event_name == ''workflow_dispatch'' ||

      (github.event_name == ''schedule'' && github.repository == ''apache/beam'')
      ||

      github.event.comment.body == ''Run Java ParquetIO Performance Test HDFS''

      '
    name: ${{ matrix.job_name }} (${{ matrix.job_phrase }})
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
    - continue-on-error: true
      name: Setup repository
      uses: ./.github/actions/setup-action
      with:
        comment_phrase: ${{ matrix.job_phrase }}
        github_job: ${{ matrix.job_name }} (${{ matrix.job_phrase }})
        github_token: ${{ secrets.GITHUB_TOKEN }}
    - continue-on-error: true
      name: Setup environment
      uses: ./.github/actions/setup-environment-action
    - continue-on-error: true
      id: auth
      name: Authenticate on GCP
      uses: google-github-actions/auth@v1
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}
        project_id: ${{ secrets.GCP_PROJECT_ID }}
    - continue-on-error: true
      name: Set k8s access
      uses: ./.github/actions/setup-k8s-access
      with:
        k8s_namespace: ${{ matrix.job_name }}-${{ github.run_id }}
    - continue-on-error: true
      id: install_hadoop
      name: Install Hadoop
      run: 'kubectl apply -f ${{ github.workspace }}/.test-infra/kubernetes/hadoop/LargeITCluster/hdfs-multi-datanode-cluster.yml

        kubectl wait svc/hadoop --for=jsonpath=''{.status.loadBalancer.ingress[0].ip}''
        --timeout=120s

        loadbalancer_IP=$(kubectl get svc hadoop -o jsonpath=''{.status.loadBalancer.ingress[0].ip}'')

        echo hadoop_IP=$loadbalancer_IP >> $GITHUB_OUTPUT

        '
    - continue-on-error: true
      name: Prepare test arguments
      uses: ./.github/actions/test-arguments-action
      with:
        argument-file-paths: '${{ github.workspace }}/.github/workflows/performance-tests-pipeline-options/parquetIOIT_HDFS.txt

          '
        arguments: '--filenamePrefix=hdfs://${{ steps.install_hadoop.outputs.hadoop_IP
          }}:9000/TEXTIO_IT_

          --hdfsConfiguration=[{\\\"fs.defaultFS\\\":\\\"hdfs:${{ steps.install_hadoop.outputs.hadoop_IP
          }}:9000\\\",\\\"dfs.replication\\\":1}]

          '
        test-language: java
        test-type: performance
    - continue-on-error: true
      name: run integrationTest
      uses: ./.github/actions/gradle-command-self-hosted-action
      with:
        arguments: '--tests org.apache.beam.sdk.io.parquet.ParquetIOIT \

          --info \

          -Dfilesystem=hdfs \

          -DintegrationTestRunner=dataflow \

          -DintegrationTestPipelineOptions=''[${{ env.beam_PerformanceTests_ParquetIOIT_HDFS_test_arguments_1
          }}]'''
        gradle-command: :sdks:java:io:file-based-io-tests:integrationTest
    strategy:
      matrix:
        job_name:
        - beam_PerformanceTests_ParquetIOIT_HDFS
        job_phrase:
        - Run Java ParquetIO Performance Test HDFS
    timeout-minutes: 100
name: PerformanceTests ParquetIOIT HDFS
on:
  repository_dispatch:
    types: trigger-ga___beam_PerformanceTests_ParquetIOIT_HDFS.yml
permissions:
  actions: write
  checks: write
  contents: read
  deployments: read
  discussions: read
  id-token: none
  issues: write
  packages: read
  pages: read
  pull-requests: write
  repository-projects: read
  security-events: read
  statuses: read
