concurrency:
  cancel-in-progress: true
  group: ${{ github.workflow }} @ ${{ github.event.issue.number || github.sha || github.head_ref
    || github.ref }}-${{ github.event.schedule || github.event.comment.id || github.event.sender.login
    }}
env:
  DEVELOCITY_ACCESS_KEY: ${{ secrets.GE_ACCESS_TOKEN }}
  GRADLE_ENTERPRISE_CACHE_PASSWORD: ${{ secrets.GE_CACHE_PASSWORD }}
  GRADLE_ENTERPRISE_CACHE_USERNAME: ${{ secrets.GE_CACHE_USERNAME }}
  INFLUXDB_USER: ${{ secrets.INFLUXDB_USER }}
  INFLUXDB_USER_PASSWORD: ${{ secrets.INFLUXDB_USER_PASSWORD }}
jobs:
  beam_Inference_Python_Benchmarks_Dataflow:
    if: 'github.event_name == ''workflow_dispatch'' ||

      (github.event_name == ''schedule'' && github.repository == ''apache/beam'')
      ||

      github.event.comment.body == ''Run Inference Benchmarks''

      '
    name: ${{ matrix.job_name }} (${{ matrix.job_phrase }})
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
    - continue-on-error: true
      name: Setup repository
      uses: ./.github/actions/setup-action
      with:
        comment_phrase: ${{ matrix.job_phrase }}
        github_job: ${{ matrix.job_name }} (${{ matrix.job_phrase }})
        github_token: ${{ secrets.GITHUB_TOKEN }}
    - continue-on-error: true
      name: Setup Python environment
      uses: ./.github/actions/setup-environment-action
      with:
        python-version: default
    - continue-on-error: true
      name: Prepare test arguments
      uses: ./.github/actions/test-arguments-action
      with:
        argument-file-paths: '${{ github.workspace }}/.github/workflows/load-tests-pipeline-options/beam_Inference_Python_Benchmarks_Dataflow_Pytorch_Vision_Classification_Resnet_101.txt

          ${{ github.workspace }}/.github/workflows/load-tests-pipeline-options/beam_Inference_Python_Benchmarks_Dataflow_Pytorch_Imagenet_Classification_Resnet_152.txt

          ${{ github.workspace }}/.github/workflows/load-tests-pipeline-options/beam_Inference_Python_Benchmarks_Dataflow_Pytorch_Language_Modeling_Bert_Base_Uncased.txt

          ${{ github.workspace }}/.github/workflows/load-tests-pipeline-options/beam_Inference_Python_Benchmarks_Dataflow_Pytorch_Language_Modeling_Bert_Large_Uncased.txt

          ${{ github.workspace }}/.github/workflows/load-tests-pipeline-options/beam_Inference_Python_Benchmarks_Dataflow_Pytorch_Imagenet_Classification_Resnet_152_Tesla_T4_GPU.txt

          '
        test-language: python
        test-type: load
    - continue-on-error: true
      name: get current time
      run: echo "NOW_UTC=$(date '+%m%d%H%M%S' --utc)" >> $GITHUB_ENV
    - continue-on-error: true
      name: run Pytorch Vision Classification with Resnet 101
      timeout-minutes: 180
      uses: ./.github/actions/gradle-command-self-hosted-action
      with:
        arguments: '-PloadTest.mainClass=apache_beam.testing.benchmarks.inference.pytorch_image_classification_benchmarks
          \

          -Prunner=DataflowRunner \

          -PpythonVersion=3.8 \

          -PloadTest.requirementsTxtFile=apache_beam/ml/inference/torch_tests_requirements.txt
          \

          ''-PloadTest.args=${{ env.beam_Inference_Python_Benchmarks_Dataflow_test_arguments_1
          }} --job_name=benchmark-tests-pytorch-imagenet-python-101-${{env.NOW_UTC}}
          --output=gs://temp-storage-for-end-to-end-tests/torch/result_resnet101-${{env.NOW_UTC}}.txt''
          \

          '
        gradle-command: :sdks:python:apache_beam:testing:load_tests:run
    - continue-on-error: true
      name: run Pytorch Imagenet Classification with Resnet 152
      timeout-minutes: 180
      uses: ./.github/actions/gradle-command-self-hosted-action
      with:
        arguments: '-PloadTest.mainClass=apache_beam.testing.benchmarks.inference.pytorch_image_classification_benchmarks
          \

          -Prunner=DataflowRunner \

          -PpythonVersion=3.8 \

          -PloadTest.requirementsTxtFile=apache_beam/ml/inference/torch_tests_requirements.txt
          \

          ''-PloadTest.args=${{ env.beam_Inference_Python_Benchmarks_Dataflow_test_arguments_2
          }} --job_name=benchmark-tests-pytorch-imagenet-python-152-${{env.NOW_UTC}}
          --output=gs://temp-storage-for-end-to-end-tests/torch/result_resnet152-${{env.NOW_UTC}}.txt''
          \

          '
        gradle-command: :sdks:python:apache_beam:testing:load_tests:run
    - continue-on-error: true
      name: run Pytorch Language Modeling using Hugging face bert-base-uncased model
      timeout-minutes: 180
      uses: ./.github/actions/gradle-command-self-hosted-action
      with:
        arguments: '-PloadTest.mainClass=apache_beam.testing.benchmarks.inference.pytorch_language_modeling_benchmarks
          \

          -Prunner=DataflowRunner \

          -PpythonVersion=3.8 \

          -PloadTest.requirementsTxtFile=apache_beam/ml/inference/torch_tests_requirements.txt
          \

          ''-PloadTest.args=${{ env.beam_Inference_Python_Benchmarks_Dataflow_test_arguments_3
          }} --job_name=benchmark-tests-pytorch-language-modeling-bert-base-uncased-${{env.NOW_UTC}}
          --output=gs://temp-storage-for-end-to-end-tests/torch/result_bert_base_uncased-${{env.NOW_UTC}}.txt''
          \

          '
        gradle-command: :sdks:python:apache_beam:testing:load_tests:run
    - continue-on-error: true
      name: run Pytorch Langauge Modeling using Hugging Face bert-large-uncased model
      timeout-minutes: 180
      uses: ./.github/actions/gradle-command-self-hosted-action
      with:
        arguments: '-PloadTest.mainClass=apache_beam.testing.benchmarks.inference.pytorch_language_modeling_benchmarks
          \

          -Prunner=DataflowRunner \

          -PpythonVersion=3.8 \

          -PloadTest.requirementsTxtFile=apache_beam/ml/inference/torch_tests_requirements.txt
          \

          ''-PloadTest.args=${{ env.beam_Inference_Python_Benchmarks_Dataflow_test_arguments_4
          }} --job_name=benchmark-tests-pytorch-language-modeling-bert-large-uncased-${{env.NOW_UTC}}
          --output=gs://temp-storage-for-end-to-end-tests/torch/result_bert_large_uncased-${{env.NOW_UTC}}.txt''
          \

          '
        gradle-command: :sdks:python:apache_beam:testing:load_tests:run
    - continue-on-error: true
      name: run Pytorch Imagenet Classification with Resnet 152 with Tesla T4 GPU
      timeout-minutes: 180
      uses: ./.github/actions/gradle-command-self-hosted-action
      with:
        arguments: '-PloadTest.mainClass=apache_beam.testing.benchmarks.inference.pytorch_image_classification_benchmarks
          \

          -Prunner=DataflowRunner \

          -PpythonVersion=3.8 \

          -PloadTest.requirementsTxtFile=apache_beam/ml/inference/torch_tests_requirements.txt
          \

          ''-PloadTest.args=${{ env.beam_Inference_Python_Benchmarks_Dataflow_test_arguments_5
          }} --job_name=benchmark-tests-pytorch-imagenet-python-gpu-${{env.NOW_UTC}}
          --output=gs://temp-storage-for-end-to-end-tests/torch/result_resnet152_gpu-${{env.NOW_UTC}}.txt'''
        gradle-command: :sdks:python:apache_beam:testing:load_tests:run
    strategy:
      matrix:
        job_name:
        - beam_Inference_Python_Benchmarks_Dataflow
        job_phrase:
        - Run Inference Benchmarks
    timeout-minutes: 900
name: Inference Python Benchmarks Dataflow
on:
  repository_dispatch:
    types: trigger-ga___beam_Inference_Python_Benchmarks_Dataflow.yml
permissions:
  actions: write
  checks: read
  contents: read
  deployments: read
  discussions: read
  id-token: none
  issues: read
  packages: read
  pages: read
  pull-requests: read
  repository-projects: read
  security-events: read
  statuses: read
